{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a32a4037-4ea0-4c02-b287-4ab6ac729659",
   "metadata": {},
   "source": [
    "## **Efficient Programming in Python**\n",
    "--- \n",
    "The topic of this notebook is efficient programming in Python. In real life most people when trying to solve a programming problem are less concerned with the efficiency of the solution than the actual solution. Our process is somewhat like this: \n",
    "\n",
    " 1. We receive the problem.\n",
    " 2. We conceive a solution.\n",
    " 3. We test the solution for correctness.\n",
    " 4. The solution goes to production.\n",
    " 5. We discover that the solution uses a lot of resources in production and/or is extremely slow.\n",
    " 6. We refactor our solution to increase speed and to reduce resource usage.\n",
    " \n",
    "In todays practice of agile software development I am not even sure that this is against best practice. In fact it seems almost that we should not spend too much time at point two, architecture an underated endeavour. My opinion would be to not go straight to a MVP, but to consider carefully how we built our solution. To take efficiency in both in time and space serious from the design up. Perhaps even before, at the choice of programming language. In case you program in Python, a quick way to improve the speed of your program is not to program in Python. If you move to a compiled language without garabage collection, you will increase the speed tremedously. Of course there are some risks involved, with that approach and since these notebooks are about Python we shall continue with efficiency in Python.\n",
    "\n",
    "There are two levels of solutions to create efficient programs. At a deep level we can implement concurrency, program asynchronously or parallel. Of course, programming like that brings issues, at minimum a programmer needs to be very well versed in that technology to not make seriously costly mistakes. Though I want to discuss asynchronous programming (I find these subjects interesting), there is another manner with which to tackle the issues of inefficiency. These are higher level solutions, involving programming techniques such as:\n",
    "\n",
    " * Optimization \n",
    " * Heuristics\n",
    " * Greedy algorithms \n",
    " * Dynamic programming \n",
    " * Using the correct data structures\n",
    "\n",
    "These are still not always easy solutions, they need more thought, blow up your code base, and need practice. This notebook is about using these to create more efficient code. Below an example of simple direct search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6162ef90-401e-46d6-a517-2144a14d1751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.85 s ± 424 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "from typing import Any\n",
    "\n",
    "def lin_search(lst:list[Any],element:Any)->bool:\n",
    "    for v in lst:\n",
    "        if v == element:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "lst = [*range(1,100_000_000)]\n",
    "%timeit lin_search(lst,59_674_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b0b91c-403d-440f-9b8a-703e0dc59a91",
   "metadata": {},
   "source": [
    "Now the same problem coded up with binary search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dea33929-b73d-40dc-96e2-5f75e4773daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 µs ± 6.82 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def binary_search(lst:list[Any],element:Any)->bool:\n",
    "    def search(lst:list[Any],element:Any,low:int,high:int)-> bool:\n",
    "        if high == low: \n",
    "            return lst[low] == element\n",
    "        mid = (high + low) // 2\n",
    "        if lst[mid] == element: \n",
    "            return True\n",
    "        elif lst[mid] > element:\n",
    "            if low == mid: # the search has exhausted\n",
    "                return False\n",
    "            else:\n",
    "                return search(lst,element,low,mid-1) \n",
    "        else:\n",
    "            return search(lst,element,mid+1,high)\n",
    "    \n",
    "    if len(lst) == 0:\n",
    "        return False\n",
    "    else:\n",
    "        return search(lst,element,0, len(lst)-1)\n",
    "\n",
    "%timeit binary_search(lst,59_674_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107a4f41-d5be-468d-9e9b-af15b1723c21",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **Analysis of algorithms; the shortest introduction ever**\n",
    "As you can see, we have moved from second to microsecond, that is a million times faster. Binary search is not even the fastest algorithm possible, for instance, merge sort is faster. I am not that interested in the \"fastest\", you should assume Python has implemented the fasted algorithm for general circumstances. If Timsort (the sorting algorithm that Python implemented) does not meet your needs, you will know more than I do both about programming and mathematics, you should write notebooks, I will read them :-). \n",
    "\n",
    "What I am interested in is to show you several programming techniques with examples and give you an insight why these are more efficient. To do that I have to introduce you very quickly to the technique used to analyse algorithms. Firstly, when we analyse algorithms, we are foremostly interested in the running time of the algorithm, secondary is the space in memory the algorithm requires. I will use `%timeit` just to have an experimental way if showing code is faster or slower. Experimenting, though fun, is not the way to analyse algorithms. After all, speed would definitely be influenced on the hardware (mine is old and not that fast, yet beautiful and loved) but also on the input size. Waiting however, is boring, so we cannot use enormous input sizes.\n",
    "\n",
    "Luckily enough for us some people already thought of the tools you need to analyse algorithms based upon on a high-level description of the algorithm. To do that we first consider all the things we think are primitive operations. We will define the following as primitive operations:\n",
    "\n",
    " * Assigning an identifier to an object\n",
    " * Determining the object associated with an identifier\n",
    " * Performing an arithmetic operation (e.g., adding two numbers)\n",
    " * Comparing two numbers\n",
    " * Accessing a single element of a Python list by index\n",
    " * Calling a function / method (excluding operations executed within the function)\n",
    " * Returning from a function / method\n",
    "\n",
    "All these primitive operations are executed in constant time. With this in mind we can straight away see why binary search is so much faster than linear search. The latter needs to do nearly sixty million constant operations. The former basically divides the list in two, sees if the element wanted is bigger or smaller than the middle, moves over to whatever is the case and repeats the operation until the number is found or there are no more numbers.\n",
    "\n",
    "{ `binary_search([50,000,000, ..., 100,000,000], 59,674,000)` }    \n",
    "{ `binary_search([50,000,000, ..., 75,000,000], 59,674,000)` }    \n",
    "{ `binary_search([50,000,000, ..., 62,500,000], 59,674,000)` }    \n",
    "{ `binary_search([56,200,000, ..., 62,500,000], 59,674,000)` }    \n",
    "{ `binary_search([59,300,000, ..., 62,500,000], 59,674,000)` }    \n",
    " \n",
    "It takes 26 runs of binary search to find the target, linear search still will have 59,673,974 runs to go. This is a trade-off you quite often see; your code will get more verbose as the solution becomes more efficient.\n",
    "\n",
    "When we analyse algorithms, it is easiest to assume worst case scenarios. It is often easy to identify a worst-case scenario. Furthermore, if you design algorithms to perform good (as good as can be achieved) for worst case, then obviously they will perform better in better scenarios. Big O notation gives us the worst-case scenario for the time an algorithm needs to compute a computation.\n",
    "\n",
    "It is typical to use seven functions to describe speed of algorithms.\n",
    "\n",
    " 1. $f(n) = c \\rightarrow O(1)$ constant time is important because it signals the number of steps needed to do a basic operation, e.g., add two numbers together.\n",
    " 2. $f(n)=log_b(n) \\rightarrow O(log_2(n))$ Where the running time of an algorithm is a logarithmic to the input size, if n is 128, that $log_2(128)=7$  \n",
    " 3. $f(n) = n \\rightarrow O(n)$ linear time the running time is proportional to the input $O(128)=128$ \n",
    " 4. $f(n) = n \\times log(n)  \\rightarrow n \\times O(log(n))$ NlogN is an intermediary function; This function grows a little more rapidly than the linear function and a lot less rapidly than the quadratic function. An algorithm that has a worst-case running time of NlogN is very much preferable over quadratic time. $ 7 \\times 128 = 896$ while $128^2 = 16384$ or roughly 18 times as much with a very small input size.  \n",
    " 5. $f(n) = n^2 \\rightarrow O(n^2)$ Quadratic time, an algorithm in quadratic time would take a million CPU cycles if the input n is a mere thousand.\n",
    " 5. $f(n) = n^3 \\rightarrow O(n^3)$ Cubic time, an algorithm in cubic time would take a billion CPU cycles on the same input $n = 1000$\n",
    " 7. $f(n) = 2^n \\rightarrow O(2^n)$ Exponential time, an algorithm in quadratic time would take with input $n = 1000$, a number with 302 digits, cycles of the CPU to compute a solution. \n",
    "\n",
    "You might think that a programmatic solution with exponential time is per definition bad, but sometimes it is simply the best performance possible e.g., determine matrix chain multiplication. To determine the order with which we multiply matrices is exponential. In artificial intelligence several standard graph search algorithms are exponential in time/space. For instance, is breadth first search https://en.wikipedia.org/wiki/Breadth-first_search is exponential in space. \n",
    "\n",
    "That doesn't always matter the best-case scenario might be much better and the worsrt case scenario very rare. There might be optimizations on the algorithm we can perform. It is about these optimization techniques that this notebook is all about. For instance, when we went from linear search ($O(n)$) to binary search ($O(log(n))$) and increased the speed of our solution a million-fold by adding a few lines of code. Of course, the solution depends on both lists being sorted, and you should notice that in the best-case scenario linear search is faster, it would have `1` straight away. \n",
    "\n",
    "I do not want to say more, this is enough to understand when I say that algorithm or data structure is fast or slow and give you the big Oh. To do actual algorithm analysis requires a university course. Stanford does a MOOC about the subject, https://online.stanford.edu/courses/soe-ycsalgorithms1-algorithms-design-and-analysis-part-1 if you are interested.\n",
    "\n",
    "Let's start with a true story.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe04fea5-0d94-430f-80e6-0902755c498d",
   "metadata": {},
   "source": [
    "#### **Croc and Pinky are going to rob the butcher (Optimization)**\n",
    "There are great snackies inside the butcher which need to be rescued and eaten. Croc has considered it and gave the following values to the goodies in the butcher shop:\n",
    " * Tenderloin - 175\n",
    " * Shoulder of lamb - 90\n",
    " * Porkbelly - 20\n",
    " * Surloin - 50\n",
    " * Sausage - 10 \n",
    " * Cote du Boeuf - 200\n",
    "\n",
    "Pinky, being the sensible one, has noted how much there is of each item by weight:\n",
    " * Tenderloin - 10\n",
    " * Shoulder of lamb - 9\n",
    " * Porkbelly - 4\n",
    " * Surloin - 2\n",
    " * Sausage - 1 \n",
    " * Cote du Boeuf - 20\n",
    "\n",
    "Now they have a conundrum how the get the most value without exceeding the carrying limit of their innocent little baby arms and mouths (20kg the constraint). So they come to you for a solution. As you explained to Croc you can tackle this optimization problem in two ways, you can opt for the optimal solution, or you can go for the greedy one. To Croc this was nuff said, the greedy solution it had to be, as both Pinky and Croc were very greedy indeed.\n",
    "\n",
    "Let's help this hungry salty and his dragon girlfriend!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49d323b8-6876-4753-b24f-77ba7d63e350",
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint = 20\n",
    "\n",
    "from typing import NamedTuple\n",
    "\n",
    "class Item(NamedTuple):\n",
    "    name:str\n",
    "    value:int\n",
    "    weight:float\n",
    "    \n",
    "def build_items()->list[Item]:\n",
    "    meat = ['Tenderloin', 'Shoulder of lamb', 'Porkbelly', 'Surloin', 'Sausage','Cote du Boeuf']\n",
    "    values = [175,90,20,50,10,200]\n",
    "    weights = [10,9,4,25,1,20]\n",
    "    return [Item(meat[idx], values[idx], weights[idx]) for idx in range(len(meat))]\n",
    "\n",
    "items = build_items()\n",
    " \n",
    "# objective functions    \n",
    "def value(item:Item)->int:\n",
    "    return item.value\n",
    "\n",
    "def weight_inverse(item:Item)->float:\n",
    "    return 1 / item.weight\n",
    "\n",
    "def density(item:Item)->float:\n",
    "    return item.value / item.weight\n",
    "\n",
    "# The greedy solution\n",
    "def greedy(items:list[Item], constraint:int, key_func:object)->tuple[list[Item],int]:\n",
    "    items = sorted(items, key=key_func, reverse=True)\n",
    "    res = []\n",
    "    total_value, total_weight= 0.0,0.0\n",
    "    for item in items:\n",
    "        if total_weight + item.weight <= constraint:\n",
    "            res.append(item)\n",
    "            total_weight += item.weight\n",
    "            total_value += item.value\n",
    "    return res,total_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bc59eb9-f576-4cfe-8c8e-fe496592c374",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([Item(name='Cote du Boeuf', value=200, weight=20)], 200.0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greedy(items, constraint, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af6ec9a-0c60-4e6b-be59-5de89526df0b",
   "metadata": {},
   "source": [
    "Croc surely will be happy, but Pinky will be mighty ticked off as Croc never shares his cote du boeuf. \n",
    "\n",
    "She demands another objective function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e1a864a-afb4-4b9b-a0ba-9115a25d4162",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([Item(name='Sausage', value=10, weight=1),\n",
       "  Item(name='Porkbelly', value=20, weight=4),\n",
       "  Item(name='Shoulder of lamb', value=90, weight=9)],\n",
       " 120.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greedy(items, constraint, weight_inverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa569273-1669-46bb-a5f2-8d62cf2d24b2",
   "metadata": {},
   "source": [
    "Now both Croc and Pinky are angry this is simply not acceptable loot, we need another objective function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "211881f0-4dec-4528-ac16-df32a569f0d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([Item(name='Tenderloin', value=175, weight=10),\n",
       "  Item(name='Shoulder of lamb', value=90, weight=9),\n",
       "  Item(name='Sausage', value=10, weight=1)],\n",
       " 275.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greedy(items, constraint, density)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f8c61b-297d-484f-9d9e-62e8773c8a56",
   "metadata": {},
   "source": [
    "It seems the best optimizing function is a ratio of weight/value and not the value of the item itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56c4e84-db6c-41d1-8956-a522e2f608b6",
   "metadata": {},
   "source": [
    "#### **An optimal solution**\n",
    "Unfortunately when Croc learned he couldn't take the cote du boeuf he threw an epic strop and he and is girlfriend Pinky where caught by the police, again...\n",
    "To prevent any further episodes he now wants an optimal solution, the best possible in all circumstances.\n",
    "A formalization of the problem is:\n",
    " 1. Item is the pair (value,weight) they can take no more items than the constraint, of 20 kg.\n",
    " 2. The set of available items snackies, a vector I of length n represents snackies. \n",
    " \n",
    "There is a vector V of length n with binary values, if `V[i]==1` than the snacky will be taken `V[i]==0` the snacky will be left behind, but under loud protest. Now the only thing we have to do is find vector V that maximizes $\\sum_{i=0}^{n-1} V[i]*I[i].value$, subject to the constraint $\\sum_{i=0}^{n-1} V[i]*I[i].weight \\le constraint$  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6a8360-0d8d-4ebc-9a83-5985eb980d85",
   "metadata": {},
   "source": [
    "We are creating a solution in three steps.\n",
    " 1.  Create a powerset of the snackies set (all possible subsets including snackies itself and the empty set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3ed87c8-3a1c-42d2-a3a5-1d56c4a4e813",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The itertools library is very rich with useful functions, this one prevents us from having to write a powerset function ourselves\n",
    "from itertools import chain, combinations\n",
    "\n",
    "def powerset(iterable):\n",
    "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n",
    "\n",
    "pset = list(powerset(items))[1:]\n",
    "len(pset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c16ef4f-512b-4ee4-a37f-511a92fb0ba9",
   "metadata": {},
   "source": [
    "2. We remove all sets that exceed the weight constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5085865a-b17a-418e-9246-2eab12009dd8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rm_excess_weight(pset:list[tuple[Item]], constraint:int)->list[tuple[Item]]:\n",
    "    res = []\n",
    "    for items in pset:\n",
    "        weight = 0.0\n",
    "        for item in items:\n",
    "            weight += item.weight\n",
    "        if weight <= constraint:\n",
    "            res.append(items)\n",
    "    return res\n",
    "\n",
    "pset = rm_excess_weight(pset,constraint)\n",
    "len(pset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416b3012-2c41-4ed8-8330-2dd364beae79",
   "metadata": {},
   "source": [
    " 3. We select that set with best overall value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90bb9c74-aea7-4c79-a063-fbd50089c1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def snackies(pset:list[tuple[Item]])->tuple[Item]:\n",
    "    snacks = ()\n",
    "    best_value = 0.0\n",
    "    for items in pset:\n",
    "        value = 0.0\n",
    "        for item in items:\n",
    "            value += item.value\n",
    "        if value > best_value:\n",
    "            snacks = items\n",
    "            best_value = value\n",
    "    return snacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52df0f4b-cfaa-4b24-a287-da7e67a25378",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Item(name='Tenderloin', value=175, weight=10),\n",
       " Item(name='Shoulder of lamb', value=90, weight=9),\n",
       " Item(name='Sausage', value=10, weight=1))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snackies(pset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8511f0-4363-4c27-b644-0fba1bfdc1f7",
   "metadata": {},
   "source": [
    "Unfortunately for Croc, it does make sense to leave the Cote du Boeuf behind. The best value is achieved by taking the above items. \n",
    "Fortunately dragons can spit fire and Croc heeled and the butcher was succesfully robbed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c45c2d1-363b-4f2c-861b-a2ac44d8fb67",
   "metadata": {},
   "source": [
    "#### **An analysis**\n",
    "Here it ends for Croc and Pinky, but we should consider the above code.\n",
    "We wil work backwards and start considering the snackies function. We have two iterables; pset and items, in the worst case scenario we would have to traverse both completely. Resulting in worst case scenario of $O(n^2)$\n",
    " \n",
    "Now for rm_excess_weight this has only one iterable we need to traverse at worst this will take $O(n)$. \n",
    "\n",
    "Now let's look at powerset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f12a7b4e-efd2-4272-86ab-37285ddc08a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(), (1,), (1, 2), (1, 2, 3), (1, 3), (2,), (2, 3), (3,)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = set(powerset([1,2,3]))\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed8e1b90-37b2-45a9-a64a-d2736ea7a257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6e87174-3b8a-4f07-91bb-d5793299b95f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = set(powerset([1,2,3,4]))\n",
    "len(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91467bc0-2d33-4262-ba6b-8894d44588d2",
   "metadata": {},
   "source": [
    "I am sure you feel it coming but let's have a look on the powerset of a set with 5 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1093a70e-22f6-4c16-823f-427075311ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = set(powerset([*range(1,6)]))\n",
    "len(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f7aeee-2670-4e41-9feb-1c97e495cf27",
   "metadata": {},
   "source": [
    "Powerset is exponential in growth, as the input size grows the output size grows exponential $O(2^n)$.\n",
    "\n",
    "Unfortunately there is nothing we can do. Taking the powerset of a set is always exponential relative to the size of the set. So the actual algorithmic complexity of the whole code is $O(2^n) + O(n^2) + O(n)= O(2^n)$\n",
    "\n",
    "This might suprise you but as n get's bigger $O(2^n)$ quickly dwarfs $O(n^2)$ so the latter two become insignificant, so we only count the largest.\n",
    "\n",
    "Our algorithm is not very fast, mostly due to the use of the powerset. If we would optimize this code, that is the place to start, how to prevent we use a powerset? \n",
    "\n",
    "The point of the story comes back to Herbert Simon, the father of Operational Research, said:\n",
    "\n",
    "\"Models making decisions that are good enough rather than laboriously calculating the optimal result, are a better description of human behaviour.\"\n",
    "\n",
    "Programming solutions to problems often entails recognizing the pattern in the problem and applying specific programming styles to create a solution. Optimization is a very common problem for the developer to solve. For instance how many shoes a factory could produce given the material in stock, or what is the itinerary of traveling salesman?\n",
    "\n",
    "An optimization problem exists of two parts:\n",
    " 1. The objective function that is to be minimised or maximised. For instance the cost of a plane ticket between two cities when doing a search online, it needs to be the lowest possible in general.\n",
    " 2. A set of constraints that must be honored. For instance a flight from Amsterdam to Liverpool should not take 6 hours and two flight changes. This set of constraints might include the empty set. \n",
    "\n",
    "These types of problems can often be formulated in a simple manner that lead to naturally computational solutions. They are problems that occur a lot in data intensive applications.\n",
    "\n",
    "These problems are in general reducable to other well known problems, they follow the same pattern, problems with known solutions. Optimization problems can be solved with exhaustive enumerations algorithms, but because of the sheer amount of computation involved, more often than not greedy algorithms are used that deliver a fast sub-optimal but acceptable solution. In our case the greedy solution ran in $O(n)$ and yielded the same result when using density as optimizing function.\n",
    "\n",
    "Finally quite often you will find that these problems can be solved recursively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68349d5d-b7f1-44a1-aee0-d74488a0970b",
   "metadata": {},
   "source": [
    "#### **Brute force**\n",
    "The most common technique to solve a problem with computation is to use the brute computing power and force a solution, if any of course. The classic example is the one of pattern matching in a string, we are looking for:       \n",
    "`abacab`    \n",
    "in:    \n",
    "`abacaabaccabacabaabb`\n",
    "\n",
    "Now if I would have to come up with a solution I would definitely first get the solution by brute force."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e69d4cf-0499-40f0-95b8-1dbff1e62dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def brute_force_find(text:str, pattern:str)->bool:\n",
    "    n, m = len(text), len(pattern)\n",
    "    for i in range(n-m+1):\n",
    "        k = 0\n",
    "        for k in range(m):\n",
    "            if text[i+k] == pattern[k]:\n",
    "                k += 1\n",
    "        if k == m:\n",
    "            return True\n",
    "    return False\n",
    "brute_force_find('abacaabaccabacabaabb', 'abacab')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8877690d-c088-44ff-989f-5c1bfa900fa3",
   "metadata": {},
   "source": [
    "#### **Heuristics**\n",
    "This algorithm is $O(nm)$ we run two loops the outer (n-m+1) times if the size of n is much larger then m, the latter becomes insignificant so we say we run the outer loop n times. The innerloop is clear we run that m times. \n",
    "\n",
    "Now we have our brute force solution we can improve it. We could try to use some heuristics. A heuristic is any approach to problem solving or self-discovery that employs a practical method that is not guaranteed to be optimal, perfect, or rational, but is nevertheless sufficient for reaching an immediate, short-term goal or approximation (definition from Wikipedia). The easiest example of an heuristic is a direct line between two cities as a measure of distance. We all know that the distance between cities is usually not travelled in direct line, but it gives us a workable idea, to compare the distances between different cities and most of the time using our heuristic will give us an accurate sense of what city is quicker to travel to. \n",
    "\n",
    "Given our pattern `abacab` we can jump immidiately to the 6th position in `abacaabaccabacabaabb`, compare the last element of our pattern to that position; if $ a \\ne b$, we can discount all that came until then. This approach is known as the looking glass heuristic. \n",
    "\n",
    "However great that is on it's own it gives only a slight improvement, but it allows me to introduce a second heuristic, the character jump heuristic. Say that our text looks like `abacadbaccabacabaabb` now if I check the 6th character I find a `d`, `d` is not in the pattern, so I can easily conclude that the pattern will not partially be in the charachters I just jumped. Let me again jump six I am now at `abacadbacca[b]acabaabb` `b` is a character in our pattern `abacab` so I can not just jump another six. When a match is found for that last character, the algorithm continues by trying to extend the match with the second-to-last character of the pattern from where it currently is aligned with the text. I move three positions to the left comparing characters `abacadba[c]cabacabaabb`, than I meet a `c` where I suposed to get an `a`. From `abacadba[c]cabacabaabb` I jump again six positions and I arrive at `abacadbaccabac[a]baabb`. The character `a`  is part of the pattern. Now I start shifting the pattern to the left until I meet the first character in the pattern that matches `a`.\n",
    "\n",
    "`abacadbaccabac[a]baabb`    \n",
    "`----------abac[a]b-----`    \n",
    "\n",
    "The direction of the jump is dependent if we find the character before or after in the pattern. If I find the charachter in the pattern after the one I was expecting I jump to the right, otherwise I jump to the left. In our example I jump to the left. I can now simply check left and right for our pattern and find the match. \n",
    "\n",
    "This algorithm is called the Boyer-Moore algorithm. Though this algorithm is also $O(nm)$ in reality it will perform much better than our previous solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c0b61b3-4214-471e-a468-81e7ab71a416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Union\n",
    "\n",
    "def boyer_moore_find(text:str, pattern:str)->Union[bool, int]:\n",
    "    '''algorithm to find the lowest substring, return the lowest index where the substring starts\n",
    "       or False if there is no substring that matches the pattern\n",
    "       inspired by Boyer Moore'''\n",
    "    n, m = len(text), len(pattern)\n",
    "    if m == 0: return 0 # an empty pattern is always a substring \n",
    "    last = dict() # build ’last’ dictionary\n",
    "    for k in range(m):\n",
    "        last[pattern[k]] = k # later occurrence overwrites\n",
    "    # align end of pattern at index m-1 of text\n",
    "    i = m - 1\n",
    "    k = m - 1\n",
    "    while i < n:\n",
    "        if text[i] == pattern[k]: # a matching character\n",
    "            if k == 0:\n",
    "                return i # pattern begins at index i of text\n",
    "            else:\n",
    "                i -= 1\n",
    "                k -= 1 \n",
    "        else:\n",
    "            j = last.get(text[i], -1) # last(text[i]) is -1 if not found\n",
    "            i += m - min(k, j + 1) # case analysis for jump step\n",
    "            k = m - 1 # restart at end of pattern\n",
    "    return False\n",
    "boyer_moore_find('abacaabaccabacabaabb', 'abacab')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68786c8b-2743-47f5-b42a-b12341141d1c",
   "metadata": {},
   "source": [
    "\n",
    "The Boyer Moore algorithm can improved upon, as Knuth, Morris, and Pratt did with their algorithm, which performs the operation in $O(m+n)$. You should try to understand it and where it improved Boyer Moore, see https://en.wikipedia.org/wiki/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm. \n",
    "\n",
    "I am not really interested in the result as much, as I am in the process. After the fitst iteration we have a straight forward brute force solution to a problem. In the second iteration we look at the properties of our problem and came with a smarter solution by introducing some heuristics (well Boyer and Moore did). In a next iteration we could improve it futher. This is often how code gets better. However you would need to incorporate this type of process in your programming proces and you need to accept that code refactoring is not criticism on your code.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3ec468-d84b-4d02-85dd-0c5029eacaad",
   "metadata": {},
   "source": [
    "#### **Greedy algorithms**\n",
    "condider the following matrix. \n",
    "\n",
    "$\\begin{matrix}\n",
    "  a & b & c \\\\\n",
    "  d & e & f \\\\\n",
    "  g & h & i\n",
    " \\end{matrix}$\n",
    " \n",
    "Say you need to travel from a to i, you have four moves available; Left, Right, Up, and Down. Easy done in four steps, but now I give a value to all elements.\n",
    "\n",
    "$\\begin{matrix}\n",
    "  (a,0) & (b,1) & (c,1)\\\\\n",
    "  (d,2) & (e,4) & (f,6)\\\\\n",
    "  (g,2) & (h,2) & (i,1)\n",
    " \\end{matrix}$\n",
    " \n",
    "End I will ask you to find me the cheapest path. Easy you say a-d-g-h-i, 7 points. \n",
    "\n",
    "We make it a bit more difficult, we let you write a program to do this, easy you think, with the constraint that you will have to find us the best path possible in in only one go and that you can only know the cost of the nodes you are about to travel to, not the others, you can't go to a node you have already visited. \n",
    "\n",
    "The best a computer can do is make the optimal choice at every junction it needs to make a choice. Starting at a, the computer can go down at a cost of `2`, or can go right at the cost of `1`. As we are trying to minimize the cost and we have no more information available, there is only one choice that is rational; we go to `b`. From b we have again to options; `e` at a cost of `4`, or `c` at cost of `1`. The algorithm must optimize, it goes to `c`. From there we have only one choice we go to `f` at a cost of `6`. By now our cost are higher than the optimal cost. Yet this is the best we can do given our limited knowledge of the entire domain.\n",
    "\n",
    "This is an example of a greedy algorithm, always making the optimal local choice. This problem however does not have the greedy-choice property; the global optimal condition cannot be reached by a series of locally optimal choices, choices that are each the current best from among the possibilities available at the time,\n",
    "starting from a well-defined starting condition `a` in our case.\n",
    "\n",
    "There are problems that have the greedy-choice property, the most famous is the huffman code, which allows you to compress text without loosing information, see https://en.wikipedia.org/wiki/Huffman_coding. But even without having the greedy-choice property a greedy algorithm might create acceptable results.\n",
    "\n",
    "The first solution to Croc and Pinky's problem was greedy, where we used three heuristics to get a different outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecdadf7-d406-4c79-963d-bb7f46996e24",
   "metadata": {},
   "source": [
    "#### **Dynamic programming**\n",
    "Dynamic programming that is a technique used to find the optimal solution to the initial problem by solving its sub-problems and combining their solutions. Recursion is a technique with which we can break down such problems into smaller subproblems, solve them and put the end result back together. \n",
    "\n",
    "Below is an example of tail recursion, being used to calculate the product of a list of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4311ab2a-642f-4a8b-ae69-1bb038907740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 µs ± 118 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def product(numbers:list[int])->int:\n",
    "    if len(numbers) == 0:\n",
    "        return 1\n",
    "    n,*ns = numbers\n",
    "    return n * product(ns)\n",
    "\n",
    "%timeit product([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a2c1e4-44b4-49f1-af43-7d33686b3aa1",
   "metadata": {},
   "source": [
    "\n",
    "We can make a quick improvement (both in memory use and speed) by using an accumulator, which stores the intermediate results, and replacing the recursive call by a while loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9c9ed89e-1f0e-4812-b37d-8829df3ded17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506 ns ± 31.6 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def aproduct(numbers:list[int])->int:\n",
    "    acc = 1\n",
    "    for number in numbers:\n",
    "        acc *= numbers.pop()\n",
    "    return acc\n",
    "    \n",
    "%timeit aproduct([1,2,3,4,5]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbe07e0-0b99-4105-a0e1-d10d71681fb6",
   "metadata": {},
   "source": [
    "#### **Fibonacci** \n",
    "As I already said many of the problems we are talking about have a recursive nature. The classic example if the Fibonacci function below.\n",
    "This code is extremely inefficient because of the manner we recalculate all intermediate results when we recurse. Requestion only the fortieth number creates a very waiting time.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5359bdff-f02b-4662-bbc8-1316ae12da82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fibonacci(n:int)->int:\n",
    "    if n == 0:\n",
    "        return 0 \n",
    "    if n == 1:\n",
    "        return 1\n",
    "    return fibonacci(n-1) + fibonacci(n-2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1c19cb4-d26f-4370-a756-283060a85593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time fibonacci(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a44bda62-ac9a-433a-97f3-84ce80facfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6765"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time fibonacci(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b4d83ee4-4838-4171-94cd-7321b28ec191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 41.9 s\n",
      "Wall time: 41.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "102334155"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time fibonacci(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8480d1b1-0997-41bc-a4d8-d513369d11b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **Memoization**\n",
    "The technique of adding a memory structure, for instance a look-up-table, to your recursive code is called memoization. If we encounter a sub-problem that we have encountered before , we do not calculate its solution again, we read it from memory instead. Reading from memory is a constant time operation, therefore we gain speed.\n",
    "\n",
    "Working with memoization is easy for we can still use the recursive nature of the problem.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c30f9045-bdbf-415a-a082-74d78f8ec684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "102334155"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = {}\n",
    "\n",
    "def fibonacci(n:int)->int:\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    if n == 1:\n",
    "        return 1 \n",
    "    elif n in table:\n",
    "        return table[n]\n",
    "    else:\n",
    "        table[n] = fibonacci(n-1) + fibonacci(n-2)\n",
    "        return table[n]\n",
    "\n",
    "%time fibonacci(40)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a402ca99-7f56-417e-85dc-d8dee4b705a2",
   "metadata": {},
   "source": [
    "Unfortunately Python has a very limited recursion depth, because it does not do any optimization of recursion.\n",
    "\n",
    "This makes using memoization in Python not a realistic option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7de99b72-2c6d-4b8c-981f-4f8e52f75c4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mfibonacci\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[40], line 11\u001b[0m, in \u001b[0;36mfibonacci\u001b[1;34m(n)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m table[n]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 11\u001b[0m     table[n] \u001b[38;5;241m=\u001b[39m \u001b[43mfibonacci\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m fibonacci(n\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m table[n]\n",
      "Cell \u001b[1;32mIn[40], line 11\u001b[0m, in \u001b[0;36mfibonacci\u001b[1;34m(n)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m table[n]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 11\u001b[0m     table[n] \u001b[38;5;241m=\u001b[39m \u001b[43mfibonacci\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m fibonacci(n\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m table[n]\n",
      "    \u001b[1;31m[... skipping similar frames: fibonacci at line 11 (2971 times)]\u001b[0m\n",
      "Cell \u001b[1;32mIn[40], line 11\u001b[0m, in \u001b[0;36mfibonacci\u001b[1;34m(n)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m table[n]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 11\u001b[0m     table[n] \u001b[38;5;241m=\u001b[39m \u001b[43mfibonacci\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m fibonacci(n\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m table[n]\n",
      "\u001b[1;31mRecursionError\u001b[0m: maximum recursion depth exceeded"
     ]
    }
   ],
   "source": [
    "fibonacci(4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6fa49321-ffea-479e-8282-2059276f73fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getrecursionlimit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4357e5a2-7905-475e-9913-60ef231ab300",
   "metadata": {},
   "source": [
    "We can enlarge the recursion limit to say 100_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "13340d42-e217-4884-bc01-631587367cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39909473435004422792081248094960912600792570982820257852628876326523051818641373433549136769424132442293969306537520118273879628025443235370362250955435654171592897966790864814458223141914272590897468472180370639695334449662650312874735560926298246249404168309064214351044459077749425236777660809226095151852052781352975449482565838369809183771787439660825140502824343131911711296392457138867486593923544177893735428602238212249156564631452507658603400012003685322984838488962351492632577755354452904049241294565662519417235020049873873878602731379207893212335423484873469083054556329894167262818692599815209582517277965059068235543139459375028276851221435815957374273143824422909416395375178739268544368126894240979135322176080374780998010657710775625856041594078495411724236560242597759185543824798332467919613598667003025993715274875"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.setrecursionlimit(100_000)\n",
    "fibonacci(4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8eefff-5f3c-44be-a067-27e009d9f331",
   "metadata": {},
   "source": [
    "#### **Tabulation**\n",
    "However, while 100_000 might seem like a big number it really isn't. In Python recursion is than also not the manner uses for repetition, it uses iteration. For problems where recursion is natural, like product, sum or factorial or so, programming without recursion requires additional coding techniques. In an imperative language like Python the technique to use is tabulation.\n",
    "\n",
    "Tabulation starts with the base case(s), finds the optimal solutions to the problem, whose immediate sub-problem is the base case. After which it goes a level higher, combines the solutions it previously obtained and construct the optimal solutions to more complex problems. The most important for a Python programmer is that we can leave recursion and use iteration. The biggest disadvantage of using tabulation is that it is not always easy to see how we can replace a recursive pattern with tabulation.\n",
    "\n",
    "As you will see when running the next cell there is near enough no difference in running times between the accumulated product and the tabulated product algorithms. Both have an $O(n)$ running time. `aproduct` does n function calls, while `tproduct` loops over the list `ns` n-1 times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d28b9280-e053-4266-9bce-1de0a4db0812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 15.6 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "39909473435004422792081248094960912600792570982820257852628876326523051818641373433549136769424132442293969306537520118273879628025443235370362250955435654171592897966790864814458223141914272590897468472180370639695334449662650312874735560926298246249404168309064214351044459077749425236777660809226095151852052781352975449482565838369809183771787439660825140502824343131911711296392457138867486593923544177893735428602238212249156564631452507658603400012003685322984838488962351492632577755354452904049241294565662519417235020049873873878602731379207893212335423484873469083054556329894167262818692599815209582517277965059068235543139459375028276851221435815957374273143824422909416395375178739268544368126894240979135322176080374780998010657710775625856041594078495411724236560242597759185543824798332467919613598667003025993715274875"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fibonacci(n:int)->int:\n",
    "    '''tabulation example'''\n",
    "    tab = [None]*(n+2) # Just for the base case I need the table to be two bigger\n",
    "    tab[0] = 0\n",
    "    tab[1] = 1\n",
    "    for idx in range(2,n+1):\n",
    "        tab[idx] = tab[idx-1] + tab[idx-2]\n",
    "    return tab[n]\n",
    "%time fibonacci(4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b9d1ec-7815-4672-a400-b9b31bcaa231",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a42a4de-a0bc-47b6-9f3d-0ee2b4ee845b",
   "metadata": {},
   "source": [
    "#### **Knapsack problem**\n",
    "I admit it, I was lazy while writing the optimal solution to Croc's butcher problem. I used a powerset and than filtered out the unwanted results. Getting me 14 usuable sets out of an original 63. As long as I can guarantee that the input is small in size that wouldn't matter, but we should have a fast algorithm for any size input.\n",
    "\n",
    "The obvious solution is not to use a powerset, but to just use those combinations whose combined weight is less than the constraint. We would completely be able to forgo any filtering if we create a sorted result. This is a well known dynamic programming problem, called the knapsack problem: Given a bag with capacity W and a list of items along with their weights and value associated with them. The task is to fill the bag in such a manner that the max value is returned, without exceeding W. \n",
    "\n",
    "The pseudo is:   \n",
    "\n",
    "for each item 'i' starting from the end: // We recurse after all   \n",
    "$\\rightarrow$ create a new set that includes item 'i' iff the total weight < the constraint, recursively process the remaining capacity and items.    \n",
    "$\\rightarrow$ create a new set WITHOUT item 'i', and recursively process the remaining items \n",
    " \n",
    "return max(set1, set2) \n",
    "\n",
    "This is the standard recursive code, like or code it runs in  $O(2^n)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a52fd983-de5e-48e8-959c-d8ca23687824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def knapsack(values, weights, capacity):\n",
    "    \n",
    "    def recursion(values, weights, capacity, current_index):\n",
    "        # base cases\n",
    "        if capacity <= 0 or current_index >= len(values):\n",
    "            return 0\n",
    "\n",
    "        result1 = 0\n",
    "\n",
    "        if weights[current_index] <= capacity:\n",
    "            result1 = values[current_index] + recursion(values, weights, capacity - weights[current_index], current_index + 1)\n",
    "\n",
    "        result2 = recursion(values, weights, capacity, current_index + 1)\n",
    "\n",
    "        return max(result1, result2)\n",
    "    \n",
    "    return recursion(values, weights, capacity, 0)\n",
    "\n",
    "\n",
    "knapsack([1, 6, 10, 16], [1, 2, 3, 5], 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a428a4-9aff-45a3-9071-97eec2703411",
   "metadata": {},
   "source": [
    "#### **Memoization**\n",
    "trace:\n",
    "`knapsack([1, 6, 10, 16], [1, 2, 3, 5], 7)` $\\rightarrow$ `recursion([1, 6, 10, 16], [1, 2, 3, 5], 7, 0)`        \n",
    "`max(result1 = 1 + recursion([1, 6, 10, 16], [1, 2, 3, 5], 6, 1), result2 = recursion([1, 6, 10, 16], [1, 2, 3, 5], 6, 1))`  6 + recursive call $\\rightarrow$ \n",
    "max(`10 + recursion([1, 6, 10, 16], [1, 2, 3, 5], 3, 3), recursion([1, 6, 10, 16], [1, 2, 3, 5], 6, 3)`) = max(10,16) $\\rightarrow$ 6 + 16 = 22 \n",
    "\n",
    "This is a very short trace but I think you will understand. Don't worry if that takes time, it is an old problem (100+ years) most people including me had to take their sweet time to grasp the details.\n",
    "\n",
    "The above solution is exponential in time $O(2^n)$ due to the number of calls with overlapping subcalls. For instance if I call: `knapsack([1, 6, 10, 16], [1, 2, 3, 5], 7)`\n",
    "\n",
    "I will call `recursion([1, 6, 10, 16], [1, 2, 3, 5], 7)` which will fork in:\n",
    "\n",
    "result1 = 1 + `recursion([1, 6, 10, 16], [1, 2, 3, 5], 6, 1)` \n",
    "\n",
    "result2 = `recursion([1, 6, 10, 16], [1, 2, 3, 5], 6, 1)`\n",
    "\n",
    "Both calls are basically the calculation, I now perform twice, and that seeps through the entire algorithm.\n",
    "\n",
    "If we get rid of the redunancy we can improve the speed to $O(C \\times  N)$ \n",
    "\n",
    "We apply the same technique we have done before, we create a memory structure and instead recalculation partial results we just look them up. Consider the memory structure carefully. We need to keep two things in mind, we need to know the constraint and the weight that will give us the value. For instance if our capacity > 0 and our weight = 1 than our value be always 1. If on the other hand our capacity is >= 3, then our weight can be 7 and 10. We can capture that in a matrix. \n",
    "\n",
    "weight capacity 0  1  2  3  4  5  6  7     \n",
    "0 --------value 0  0  0  0  0  0  0  0    \n",
    "1 --------value 0  1  1  1  1  1  1  1    \n",
    "2 --------value 0  0  6  7  7  7  7  7      \n",
    "3 --------value 0  0  0  10 17 17 17 17     \n",
    "5 --------value 0  0  0  0  0  16 17 22     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3340b058-85a0-45fd-ad48-25b78b8ddbc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def knapsack(values, weights, capacity):\n",
    "    matrix = [[None for x in range(capacity+1)] for y in range(len(weights))]\n",
    "    \n",
    "    def recursion(matrix, values, weights, capacity, current_index):\n",
    "        # base cases\n",
    "        if capacity <= 0 or current_index >= len(values):\n",
    "            return 0\n",
    "\n",
    "        if matrix[current_index][capacity] is not None:\n",
    "            return matrix[current_index][capacity]\n",
    "\n",
    "        # recursive call after choosing the element at the currentIndex\n",
    "        # if the weight of the element at currentIndex exceeds the capacity, we\n",
    "        # shouldn't process this\n",
    "        result1 = 0\n",
    "        \n",
    "        if weights[current_index] <= capacity:\n",
    "            result1 = values[current_index] + recursion(matrix, values, weights, capacity - weights[current_index], current_index + 1)\n",
    "        \n",
    "        result2 = recursion(matrix, values, weights, capacity, current_index + 1) \n",
    "        \n",
    "        matrix[current_index][capacity] = max(result1, result2)\n",
    "        return matrix[current_index][capacity]\n",
    "        \n",
    "    \n",
    "    return recursion(matrix, values, weights, capacity, 0)\n",
    "\n",
    "\n",
    "knapsack([1, 6, 10, 16], [1, 2, 3, 5], 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2a6b93-354e-400e-b527-d096602c3d52",
   "metadata": {},
   "source": [
    "We can apply the same coding technique to Croc's problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
