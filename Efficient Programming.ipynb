{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a32a4037-4ea0-4c02-b287-4ab6ac729659",
   "metadata": {},
   "source": [
    "## **Efficient Programming in Python**\n",
    "---\n",
    "The topic of this notebook is efficient programming in Python. In real life most people when trying to solve a programming problem are less concerned with the efficiency of the solution than the actual solution. Our process is somewhat like this: \n",
    "\n",
    " 1. We receive the problem.\n",
    " 2. We conceive a solution.\n",
    " 3. We test the solution for correctness.\n",
    " 4. The solution goes to production.\n",
    " 5. We discover that the solution uses a lot of resources in production and/or is extremely slow.\n",
    " 6. We refactor our solution to increase speed and to reduce resource usage.\n",
    " \n",
    "In todays practice of agile software development I am not even sure that this is against best practice. In fact it seems almost that we should not spend too much time at point two, architecture an underated endeavour. My opinion would be to not go straight to a MVP, but to consider carefully how we built our solution. To take efficiency in both in time and space serious from the design up. Perhaps even before, at the choice of programming language. In case you program in Python, a quick way to improve the speed of your program is not to program in Python. If you move to a compiled language without garabage collection, you will increase the speed tremedously. Of course there are some risks involved, with that approach and since these notebooks are about Python we shall continue with efficiency in Python.\n",
    "\n",
    "There are two levels of solutions to create efficient programs. At a deep level we can implement concurrency, program asynchronously or parallel. Of course, programming like that brings issues, at minimum a programmer needs to be very well versed in that technology to not make seriously costly mistakes. Though I want to discuss asynchronous programming (I find these subjects interesting), there is another manner with which to tackle the issues of inefficiency. These are higher level solutions, involving programming techniques such as:\n",
    "\n",
    " * optimization \n",
    " * divide & conquer\n",
    " * greedy algorithms \n",
    " * dynamic programming \n",
    " * using the right data structures\n",
    "\n",
    "These are still not always easy solutions, they need more thought, blow up your code base, and need practice. This notebook is about using these to create more efficient code. Below an example of simple direct search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6162ef90-401e-46d6-a517-2144a14d1751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.21 s ± 673 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "from typing import Any\n",
    "\n",
    "def lin_search(lst:list[Any],element:Any)->bool:\n",
    "    for v in lst:\n",
    "        if v == element:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "lst = [*range(1,100_000_000)]\n",
    "%timeit lin_search(lst,59_674_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b0b91c-403d-440f-9b8a-703e0dc59a91",
   "metadata": {},
   "source": [
    "Now the same problem coded up with binary search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dea33929-b73d-40dc-96e2-5f75e4773daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.2 µs ± 2.22 µs per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def binary_search(lst:list[Any],element:Any)->bool:\n",
    "    \n",
    "    def search(lst:list[Any],element:Any,low:int,high:int)-> bool:\n",
    "        if high == low: \n",
    "            return lst[low] == element\n",
    "        mid = (high + low) // 2\n",
    "        if lst[mid] == element: \n",
    "            return True\n",
    "        elif lst[mid] > element:\n",
    "            if low == mid: # the search has exhausted\n",
    "                return False\n",
    "            else:\n",
    "                return search(lst,element,low,mid-1) \n",
    "        else:\n",
    "            return search(lst,element,mid+1,high)\n",
    "    \n",
    "    if len(lst) == 0:\n",
    "        return False\n",
    "    else:\n",
    "        return search(lst,element,0, len(lst)-1)\n",
    "\n",
    "%timeit binary_search(lst,59_674_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107a4f41-d5be-468d-9e9b-af15b1723c21",
   "metadata": {},
   "source": [
    "#### **Analysis the shortest introduction ever**\n",
    "As you can see we have moved from second to microsecond, that is a million times faster. Binary search is not even the fastest algorithm possible, for instance, merge sort is faster. I am not that interested in the \"fastest\" you should assume Python has implemented the fasted algorithm for general circumstances. If Timsort does not meet your needs, you will know more than I do both about programming and mathematics, you should write notebooks :-). \n",
    "\n",
    "What I am interested in is to show you several programming techniques with examples, and give you an insight why these are more efficient. To do that I have to introduce you very quickly to the technique used to analyze algorithms. Firstly when we analyze algorithms we are foremostly interested in the running time of the algorithm, secondary is the space in memory the algorithm requires. I will use `%timeit` just to have an experimental way if showing code is faster or slower. Experimenting, though fun, is not the way to analyze algorithms. After all, speed would definitely be influenced on the hardware (mine is old and not that fast, yet beautiful and loved) but also on the input size. Waiting however, is boring, so we cannot use enormous input sizes.\n",
    "\n",
    "Luckliy enough for us some people already thought of the tools you need to analyze algorithms based upon on a high level description of the algorithm. To do that we first consider all the things we think are primitive operations. We will define the following as primitive operations:\n",
    "\n",
    " * Assigning an identifier to an object\n",
    " * Determining the object associated with an identifier\n",
    " * Performing an arithmetic operation (e.g., adding two numbers)\n",
    " * Comparing two numbers\n",
    " * Accessing a single element of a Python list by index\n",
    " * Calling a function / method (excluding operations executed within the function)\n",
    " * Returning from a function / method\n",
    "\n",
    "All these primitive operations are exexcuted in constant time. With this in mind we can straight away see why binary search is so much faster than linear search. The latter needs to do nearly sixty million constant operations. The former basically divides the list in two, sees if the element wanted is bigger or smaller than the middle, moves over to whatever is the case and repeats the operation until the number is found or there are no more numbers.\n",
    "\n",
    "{ `binary_search([50,000,000, ..., 100,000,000], 59,674,000)` }\n",
    "{ `binary_search([50,000,000, ..., 75,000,000], 59,674,000)` }\n",
    "{ `binary_search([50,000,000, ..., 62,500,000], 59,674,000)` }\n",
    "{ `binary_search([56,200,000, ..., 62,500,000], 59,674,000)` }\n",
    "{ `binary_search([593,000,000, ..., 62,500,000], 59,674,000)` }\n",
    " \n",
    "Within 5 runs of the algorithm binary search is close to the target. Linear search still will have fifty-nine million and a bit steps to go.   \n",
    "\n",
    "When we analyze algorithms it is easiest to assume worst case scenarios. It is often easy to identify a worst case scenario. Furthermore if you design algorithms to perform good (as good as can be achieved) for worst case, than obviously they will perform better in better scenarios. Big O notation gives us the worst case scenario for the time an algorithm needs to compute a computation.\n",
    "\n",
    "It is typical to use seven functions to describe speed of algorithms.\n",
    "\n",
    " 1. f(n) = c $\\rightarrow O(1)$ constant time is important because it signals the amount of steps needed to do a basic operation, e.g., add two numbers together.\n",
    " 2. $O(log(n))$ or  $O(log_2(n))$ logarithmic time. We quite often see logarithmic function creeping up in analysis. Yet \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "233a653a-7653-4f6a-880c-9674b67d6d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "374000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "59674000-59300000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7dd89e-be37-4ef7-984e-d736b61207ce",
   "metadata": {},
   "source": [
    "#### Code comment\n",
    "Let's consider what happens.We receive a list and keep looking through the list and comparing elements.\n",
    "#### in this scenario we have to compare all elements in the list to element n times.With being the length of the list. \n",
    "#### We say this algorithm takes O(n) times to complete. This is worst case scenario of course if we were looking for 1 we would have found it immidiately O(1)\n",
    "#### \n",
    "#### From fastest to slowest in big O:\n",
    "#### $O(1)$ a.k.a constant time\n",
    "#### $O(log(n))$\n",
    "#### $O(n)$\n",
    "#### $O(log(n) \\times n) $\n",
    "#### $O(n^2)$ a.k.a polynomial time\n",
    "#### $O(2^n)$ a.k.a exponential time\n",
    "#### We can quite obviously do this faster with a binary search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1958e041-9b4d-42ec-adff-e285c6a04c70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80913fc-52ef-4b97-bee6-b5fe9e961185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df50f436-04f2-4071-992c-77a6f885c1c9",
   "metadata": {},
   "source": [
    "#### As we can see linear search takes roughly 3 milliseconds and binary search takes roughly a thousand times less with 5 micro seconds\n",
    "#### We can also see that binary search is much the less straight forward code\n",
    "#### Programming efficient fast code is not easy, it is often a trade off between writing simple but slow code for more complex but faster code \n",
    "#### This is important in real time systems for instance stock trading or software in cars or airplanes\n",
    "#### Most of this type of code is not written in Python, but languages like Ada and Rust\n",
    "#### In Python especially when working with large data you should know how to program efficiently to a degree\n",
    "#### This notebook is about the type of problems that can be solved efficiently"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe04fea5-0d94-430f-80e6-0902755c498d",
   "metadata": {},
   "source": [
    "## **Croc and Pinky are going to rob the butcher (Optimization)**\n",
    "#### There are great snackies inside the butcher which need to rescued and eaten. Croc has considered it and gave the following values to the goodies in the butcher shop:\n",
    "#### Tenderloin - 175\n",
    "#### Shoulder of lamb - 90\n",
    "#### Porkbelly - 20\n",
    "#### Surloin - 50\n",
    "#### Sausage - 10 \n",
    "#### Cote du Boeuf - 200\n",
    "#### Pinky being the sensible one has noted how much there is of each item and noted the weights:\n",
    "#### Tenderloin - 10\n",
    "#### Shoulder of lamb - 9\n",
    "#### Porkbelly - 4\n",
    "#### Surloin - 2\n",
    "#### Sausage - 1 \n",
    "#### Cote du Boeuf - 20\n",
    "#### Now they have a conundrum how the get the most value without exceeding the carrying limit of their innocent little baby arms and mouths (20kg the constraint)\n",
    "#### As you explained to Croc you can tackle this optimization problem in two ways, you can opt for the optimal solution, or you can go for the greedy one. To Croc this was nuff said, the greedy solution it had to be as was very greedy indeed and so was Pinky.\n",
    "#### Let's help this salty and his dragon girlfriend!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d323b8-6876-4753-b24f-77ba7d63e350",
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint = 20\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Item:\n",
    "    name:str\n",
    "    value:int\n",
    "    weight:float\n",
    "    \n",
    "def build_items()->list[Item]:\n",
    "    meat = ['Tenderloin', 'Shoulder of lamb', 'Porkbelly', 'Surloin', 'Sausage','Cote du Boeuf']\n",
    "    values = [175,90,20,50,10,200]\n",
    "    weights = [10,9,4,25,1,20]\n",
    "    items = []\n",
    "    for idx in range(len(meat)):\n",
    "        items.append(Item(meat[idx], values[idx], weights[idx]))\n",
    "    return items\n",
    "\n",
    "items = build_items()\n",
    " \n",
    "# objective functions    \n",
    "def value(item:Item)->int:\n",
    "    return item.value\n",
    "\n",
    "def weight_inverse(item:Item)->float:\n",
    "    return 1 / item.weight\n",
    "\n",
    "def density(item:Item)->float:\n",
    "    return item.value / item.weight\n",
    "\n",
    "# The greedy solution\n",
    "def greedy(items:list[Item], constraint:int, key_func:object)->tuple[list[Item],int]:\n",
    "    items = sorted(items, key=key_func, reverse=True)\n",
    "    res = []\n",
    "    total_value, total_weight= 0.0,0.0\n",
    "    for item in items:\n",
    "        if total_weight + item.weight <= constraint:\n",
    "            res.append(item)\n",
    "            total_weight += item.weight\n",
    "            total_value += item.value\n",
    "    return res,total_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc59eb9-f576-4cfe-8c8e-fe496592c374",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "greedy(items, constraint, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af6ec9a-0c60-4e6b-be59-5de89526df0b",
   "metadata": {},
   "source": [
    "#### Croc surely will be happy but Pinky will be mighty ticked off as Croc never shares his cote du boeuf\n",
    "#### She wants another objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1a864a-afb4-4b9b-a0ba-9115a25d4162",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "greedy(items, constraint, weight_inverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa569273-1669-46bb-a5f2-8d62cf2d24b2",
   "metadata": {},
   "source": [
    "#### Now both Croc and Pinky are angry this is simply not acceptable loot we need another objective function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211881f0-4dec-4528-ac16-df32a569f0d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "greedy(items, constraint, density)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f8c61b-297d-484f-9d9e-62e8773c8a56",
   "metadata": {},
   "source": [
    "#### it seems the best optimizing function is a ratio of weight/value and not the value of the item itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56c4e84-db6c-41d1-8956-a522e2f608b6",
   "metadata": {},
   "source": [
    "## **An optimal solution**\n",
    "#### Unfortunately when Croc learned he couldn't take the cote du boeuf he threw an epic hissy fit and he and is girlfriend Pinky where caught by the police, again...\n",
    "#### To prevent any further episodes he now wants an optimal solution, the best possible in all circumstances\n",
    "#### A formallization of the problem is:\n",
    "#### item is the pair (value,weight)\n",
    "#### they can take no more of the pairs than the constraint, of 20 kg\n",
    "#### There is a set of available items snackies, a vector I of length n represents snackies\n",
    "#### There is a vector V of length n with binary values, if `V[i]==1` than the snacky will be taken `V[i]==0` the snacky will be left behind, but under loud protest.\n",
    "#### Now the only thing we have to do is find vector V that maximizes $\\sum_{i=0}^{n-1} V[i]*I[i].value$ \n",
    "#### Subject to the constraint $\\sum_{i=0}^{n-1} V[i]*I[i].weight \\le constraint$  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6a8360-0d8d-4ebc-9a83-5985eb980d85",
   "metadata": {},
   "source": [
    "#### Our solution is going to be in three steps\n",
    "#### The first step to create a powerset of the snackies set (all possible subsets including snackies itself and the empty set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ed87c8-3a1c-42d2-a3a5-1d56c4a4e813",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The itertools library is very rich with useful functions, this one prevents us from having to write a powerset function our selves\n",
    "from itertools import chain, combinations\n",
    "\n",
    "def powerset(iterable):\n",
    "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n",
    "\n",
    "pset = list(powerset(items))[1:]\n",
    "len(pset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c16ef4f-512b-4ee4-a37f-511a92fb0ba9",
   "metadata": {},
   "source": [
    "#### In the second step we remove all sets that exceed the weight constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5085865a-b17a-418e-9246-2eab12009dd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rm_excess_weight(pset:list[tuple[Item]], constraint:int)->list[tuple[Item]]:\n",
    "    res = []\n",
    "    for items in pset:\n",
    "        weight = 0.0\n",
    "        for item in items:\n",
    "            weight += item.weight\n",
    "        if weight <= constraint:\n",
    "            res.append(items)\n",
    "    return res\n",
    "\n",
    "pset = rm_excess_weight(pset,constraint)\n",
    "len(pset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416b3012-2c41-4ed8-8330-2dd364beae79",
   "metadata": {},
   "source": [
    "#### As third and final step we only need to select that set with best overall value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bb9c74-aea7-4c79-a063-fbd50089c1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def snackies(pset:list[tuple[Item]])->tuple[Item]:\n",
    "    snacks = ()\n",
    "    best_value = 0.0\n",
    "    for items in pset:\n",
    "        value = 0.0\n",
    "        for item in items:\n",
    "            value += item.value\n",
    "        if value > best_value:\n",
    "            snacks = items\n",
    "            best_value = value\n",
    "    return snacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52df0f4b-cfaa-4b24-a287-da7e67a25378",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "snackies(pset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8511f0-4363-4c27-b644-0fba1bfdc1f7",
   "metadata": {},
   "source": [
    "#### Unfortunately for Croc, it does make sense to leave the Cote du Boeuf behind. The best value is achieved by taking the above items. \n",
    "#### Fortunately dragons can spit fire and Croc heeled and the butcher was succesfully robbed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c45c2d1-363b-4f2c-861b-a2ac44d8fb67",
   "metadata": {},
   "source": [
    "## **Greedy**\n",
    "#### Here it ends for Croc and Pinky but we should consider the above code.\n",
    "#### We wil work backwards and start considering snackies\n",
    "#### We have two iterables, both we would have to traverse completely in the worst case scenario. $O(n^2)$\n",
    "#### Now for rm_excess_weight this has only one iterable we need to traverse at worst this will take $O(n)$ \n",
    "#### Now we get to the kicker powerset here it is reasonably efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12a7b4e-efd2-4272-86ab-37285ddc08a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = set(powerset([1,2,3]))\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8e1b90-37b2-45a9-a64a-d2736ea7a257",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e87174-3b8a-4f07-91bb-d5793299b95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = set(powerset([1,2,3,4]))\n",
    "len(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91467bc0-2d33-4262-ba6b-8894d44588d2",
   "metadata": {},
   "source": [
    "#### I am sure you feel it coming but let's have a look on the powerset of a set with 5 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1093a70e-22f6-4c16-823f-427075311ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = set(powerset([*range(1,6)]))\n",
    "len(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f7aeee-2670-4e41-9feb-1c97e495cf27",
   "metadata": {},
   "source": [
    "#### Powerset is exponential in growth, as the input size grows the output size grows exponential $O(2^n)$\n",
    "#### Unfortunately there is nothing we can do. Taking the powerset of a set is always exponential relative to the size of the set. \n",
    "#### So the actual algorithmic complexity of the whole code is $O(2^n) + O(n^2) + O(n)= O(2^n)$\n",
    "#### This might suprise you but as n get's bigger $O(2^n)$ quickly dwarfs $O(n^2)$ so the latter two become insignificant, so we only count the largest  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecd987f-5279-4bf3-a869-1fff3543bd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "2**100, 100**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df761f20-cb65-41b3-ab62-cd2c8eafc389",
   "metadata": {},
   "source": [
    "#### The point of the story comes back to Herbert Simon who said:\n",
    "#### Models making decisions that are good enough rather than laboriously calculating the optimal result are a better description of human or Croc behaviour. We booth like to do things greedy, just accepting to take that result that is satisfying. Herbert Simon won a Nobel prize for this insight."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf79d93-6916-48eb-b707-410e6ea27cbb",
   "metadata": {},
   "source": [
    "## **Optimization**\n",
    "#### Programming solutions to problems often entails recognizing the pattern in the problem and applying specific programming styles to create a solution. \n",
    "#### Optimization is a very common problem for the developer to solve. For instance how much shoes a factory could produce given the material in stock, or what is the itinerary of travelling salesman?\n",
    "#### An optimization problem exists of two parts:\n",
    "#### 1 The objective function that is to be minimised or maximised. For instance the cost of a plane ticket between two cities when doing a search online, it needs to be the lowest possible in general.\n",
    "#### 2 A set of constraints that must be honored. For instance a flight from Amsterdam to Liverpool should not take 6 hours and two flight changes. This set of constraints might include the empty set. \n",
    "#### These types of problems are very common. They also tend to be problems that can be formulated in a simple manner that lead to naturally computational solutions. They are problems that occur a lot in data intensive applications.\n",
    "#### These problems are in general reducable to well known problems (they follow the same pattern)\n",
    "#### These problems can be solved with exhaustive enumerations algorithms, but because of the sheer amount of computation involved, more often than not greedy algorithms are used that deliver a fast sub-optimal but acceptable solution. \n",
    "#### Quite often you will find that these problems can be solved recursively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9ed89e-1f0e-4812-b37d-8829df3ded17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def product(numbers:list[int])->int:\n",
    "    return recursion(numbers,1)\n",
    "\n",
    "def recursion(numbers:list[int], acc:int)->int:\n",
    "    if len(numbers) == 1:\n",
    "        return acc*numbers[0]\n",
    "    acc = numbers.pop()*acc\n",
    "    return recursion(numbers,acc) \n",
    "product([*range(1,5),5]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8480d1b1-0997-41bc-a4d8-d513369d11b4",
   "metadata": {},
   "source": [
    "#### unfortunately Python is not the best at recursion it has a very limited recursion depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa49321-ffea-479e-8282-2059276f73fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.getrecursionlimit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4357e5a2-7905-475e-9913-60ef231ab300",
   "metadata": {},
   "source": [
    "#### We can enlarge the recursion limit to say 100_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13340d42-e217-4884-bc01-631587367cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.setrecursionlimit(100_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8eefff-5f3c-44be-a067-27e009d9f331",
   "metadata": {},
   "source": [
    "#### However while 100_000 might seem like a big number it really isn't.\n",
    "#### In Python recursion is also not the manner with which Python handles repitition, it uses iteration\n",
    "#### However for problems where recursion is natural, like product, sum or factorial or so, programming without recursion requires additional coding techniques \n",
    "#### Techniques like memoization and tabulation that create a solution optimized for Python "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ebecf3-f078-4d0c-9257-8fd9e7d34640",
   "metadata": {},
   "source": [
    "## **Tabulation example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28b9280-e053-4266-9bce-1de0a4db0812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tab_product(ns:list[int])->int:\n",
    "    l = len(ns)\n",
    "    tab = [None]*(l+1)\n",
    "    tab[0] = 1\n",
    "    for idx in range(1,l+1):\n",
    "        tab[idx] = ns[idx-1] * tab[idx-1]\n",
    "    return tab[l]\n",
    "tab_product([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63957f67-b0c7-4827-a68e-2878cf519220",
   "metadata": {},
   "source": [
    "## **Memoization example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9fa192-e8ae-4953-b4e3-4a8a70fbee9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "memoization = {}\n",
    "\n",
    "def mem_product(ns:list[int])->int:\n",
    "    memoization[0] = ns[0]\n",
    "    for idx in range(1,len(ns)):\n",
    "        memoization[idx] = ns[idx]*memoization[idx-1]\n",
    "    return memoization[len(ns)-1]\n",
    "mem_product([1,2,3,4,5])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a783993-2f60-41b7-9764-029e2896e506",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ls = [i for i in range(10,10_000,10)]\n",
    "%time mem_product(ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d849f7c3-9a85-4ab2-bbf2-955634569def",
   "metadata": {},
   "source": [
    "#### In general the method is as follows, first follow the natural pattern and create a solution using recursion\n",
    "#### Once you have developed that solution we can optimize it for use with Python by reimplementing the solution using tabulation or memoisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0aaf0d-ef90-4270-a3a5-dfccbd36538f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
